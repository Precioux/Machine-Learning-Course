{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1968e7d",
   "metadata": {},
   "source": [
    "# Decision Tree explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594368d6",
   "metadata": {},
   "source": [
    "Classification is a two-step process, learning step and prediction step, in machine learning. In the learning step, the model is developed based on given training data. In the prediction step, the model is used to predict the response for given data. Decision Tree is one of the easiest and popular classification algorithms to understand and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d687e",
   "metadata": {},
   "source": [
    "## Types of Decision Trees\n",
    "Types of decision trees are based on the type of target variable we have. It can be of two types:\n",
    "\n",
    "- Categorical Variable Decision Tree: Decision Tree which has a categorical target variable then it called a Categorical variable decision tree.\n",
    "- Continuous Variable Decision Tree: Decision Tree has a continuous target variable then it is called Continuous Variable Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26054853",
   "metadata": {},
   "source": [
    "## Important Terminology related to Decision Trees\n",
    " \n",
    "- Root Node: It represents the entire population or sample and this further gets divided into two or more homogeneous sets.\n",
    "- Splitting: It is a process of dividing a node into two or more sub-nodes.\n",
    "- Decision Node: When a sub-node splits into further sub-nodes, then it is called the decision node.\n",
    "- Leaf / Terminal Node: Nodes do not split is called Leaf or Terminal node.\n",
    "- Pruning: When we remove sub-nodes of a decision node, this process is called pruning. You can say the opposite process of splitting.\n",
    "- Branch / Sub-Tree: A subsection of the entire tree is called branch or sub-tree.\n",
    "- Parent and Child Node: A node, which is divided into sub-nodes is called a parent node of sub-nodes whereas sub-nodes are the child of a parent node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0fc10",
   "metadata": {},
   "source": [
    "## Assumptions while creating Decision Tree\n",
    "Below are some of the assumptions we make while using Decision tree:\n",
    "\n",
    "- In the beginning, the whole training set is considered as the root.\n",
    "- Feature values are preferred to be categorical. If the values are continuous then they are discretized prior to building the model.\n",
    "- Records are distributed recursively on the basis of attribute values.\n",
    "- Order to placing attributes as root or internal node of the tree is done by using some statistical approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192297ab",
   "metadata": {},
   "source": [
    "## How do Decision Trees work?\n",
    "The decision of making strategic splits heavily affects a treeâ€™s accuracy. The decision criteria are different for classification and regression trees.\n",
    "\n",
    "Decision trees use multiple algorithms to decide to split a node into two or more sub-nodes. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that the purity of the node increases with respect to the target variable. The decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960088b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
